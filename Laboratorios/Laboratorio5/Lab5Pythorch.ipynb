{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyORgWHVWNNi3bv4poTddXeh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Laboratorio 5 Redes Neuronales con Pythorch (Grupo 1)\n"," <h3>Implementacion del codigo del redes neuronales con pythorch, este modelo busca realizar la prediccion de imagenes de Lenguaje de Señas<h3>\n"," <HR>\n"," <h3>\n","  NOMBRE: Delgadillo LLanos Juan Sebastian <br>\n","  CARRERA: Ingenieria de Sistemas <BR>\n","  \n","  * [Enlace al git hub](https://github.com/sebastianDLL/SIS420_IA/tree/main)\n","  \n","  * [Enlace al Colab](https://colab.research.google.com/drive/1FCdaWCkDDFZZzGjhiWusWytvKDVjWw1U?usp=sharing)\n"," <h3>"],"metadata":{"id":"CDQxGOzTAk8o"}},{"cell_type":"markdown","source":["# IMPORTAMOS LIBRERIAS PARA EL EJERCICIO"],"metadata":{"id":"cryJYUuuBMw2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB9V2ofUY6jT","executionInfo":{"status":"ok","timestamp":1714587746574,"user_tz":240,"elapsed":38530,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"9ec68580-8bdc-43d3-d7ac-535068c4acd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","# Libreria para graficos\n","from matplotlib import pyplot as plt\n","\n","\n","import torch\n","from torch import optim  # For optimizers like SGD, Adam, etc.\n","from torch import nn  # All neural network modules\n","from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n","\n","import torchvision # torch package for vision related things\n","import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n","import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n","import torchvision.datasets as datasets  # Standard datasets\n","from tqdm import tqdm  # For nice progress bar!\n","\n","from torchvision.datasets import ImageFolder\n","\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline\n","\n","# conectamos al drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Iniciamos la clase RedNeuronalMLS, definiendo las capas correspondientes\n","\n"],"metadata":{"id":"CvkU2_srBVzG"}},{"cell_type":"code","source":["# Here we create our simple neural network. For more details here we are subclassing and\n","# inheriting from nn.Module, this is the most general way to create your networks and\n","# allows for more flexibility. I encourage you to also check out nn.Sequential which\n","# would be easier to use in this scenario but I wanted to show you something that\n","# \"always\" works.\n","class RedNeuronalMLS(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(RedNeuronalMLS, self).__init__()\n","        # Our first linear layer take input_size, in this case 160.000 x 3 --> 480000 nodes to 30\n","        # and our second linear layer takes 30 to the num_classes we have, in\n","        # this case 10.\n","        self.fc1 = nn.Linear(input_size, 50)\n","        self.fc2 = nn.Linear(50, num_classes)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x here is the mnist images and we run it through fc1, fc2 that we created above.\n","        we also add a ReLU activation function in between and for that (since it has no parameters)\n","        I recommend using nn.functional (F)\n","        \"\"\"\n","        x = self.fc1(x)\n","        x = F.sigmoid(x)\n","        # x = F.sigmoid(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"OvfeJuZ7ZDyY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Asignamos el dispositivo (GPU o CPU)\n","Tambien definimos la capa de entrada que seria 480000 porque nuestras imagenes son de 400x400 y son a colores lo que debemos multiplicar por 3"],"metadata":{"id":"5xpj5d4JBj32"}},{"cell_type":"code","source":["# Set device cuda for GPU if it's available otherwise run on the CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Hyperparameters of our neural network which depends on the dataset, and\n","# also just experimenting to see what works well (learning rate for example).\n","input_size = 480000  #400x400x3 --> rgb   400x400 --> grises\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 50000\n","num_epochs = 15"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbS1CTTXZFgn","executionInfo":{"status":"ok","timestamp":1714588540129,"user_tz":240,"elapsed":379,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"7da2d693-3a29-47f0-9aff-ec521e49a083"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["LEEMOS EL DATASET DE IMAGENES SEPARANDO PARA ENTRENAMIENTO Y PARA PROBAR\n","\n","(80% - 20%)"],"metadata":{"id":"z-7c0hAnCDjH"}},{"cell_type":"code","source":["# Definir la transformación para convertir las imágenes a tensores\n","transformacion = transforms.Compose([\n","    #transforms.Resize((400, 400)),  # Redimensionar las imágenes a un tamaño específico\n","    transforms.ToTensor()            # Convertir a tensor\n","])\n","\n","# Rutas a las carpetas de entrenamiento y prueba\n","ruta_train = \"/content/drive/MyDrive/SIS420/LABORATORIOS/Lab5/asl_dataset/train\"\n","ruta_test = \"/content/drive/MyDrive/SIS420/LABORATORIOS/Lab5/asl_dataset/test\"\n","\n","# Crear conjuntos de datos de imagen para entrenamiento y prueba\n","train_dataset = ImageFolder(root=ruta_train, transform=transformacion)\n","test_dataset = ImageFolder(root=ruta_test, transform=transformacion)\n","\n","# Crear DataLoader para entrenamiento y prueba\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n","\n","print(\"Número de imágenes de entrenamiento:\", len(train_dataset))\n","print(\"Número de imágenes de prueba:\", len(test_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NslVVFydZudx","executionInfo":{"status":"ok","timestamp":1714588420569,"user_tz":240,"elapsed":511,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"67ec542e-89c6-427a-954a-d4cd8f447f11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de imágenes de entrenamiento: 560\n","Número de imágenes de prueba: 140\n"]}]},{"cell_type":"markdown","source":["# **INICIAMOS LA RED NEURONAL**"],"metadata":{"id":"TS3zb5m6CSOH"}},{"cell_type":"code","source":["# Initialize network\n","model = RedNeuronalMLS(input_size=input_size, num_classes=num_classes).to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UezCfTqZxcv","executionInfo":{"status":"ok","timestamp":1714588423140,"user_tz":240,"elapsed":395,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"2ed95367-4e0a-4fa6-b511-b867c205eda9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RedNeuronalMLS(\n","  (fc1): Linear(in_features=480000, out_features=50, bias=True)\n","  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Definir la función de pérdida y el optimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"8s64OFpMZ0CA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Network\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n","    # for batch_idx, (data, targets) in enumerate(train_loader):\n","\n","        # Get data to cuda if possible\n","        data = data.to(device=device)\n","        targets = targets.to(device=device)\n","\n","        # print(data.shape)\n","        # Get to correct shape\n","        data = data.reshape(data.shape[0], -1)\n","        print(data.shape)\n","        # print(\"-\"*30)\n","        # forward\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # gradient descent or adam step\n","        optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FuxIiEWLZ3o3","executionInfo":{"status":"ok","timestamp":1714588664149,"user_tz":240,"elapsed":120554,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"67e8b923-705f-457a-cee7-760824f85d43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:10<00:00, 10.70s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:08<00:00,  8.13s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:09<00:00,  9.45s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.32s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.63s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.80s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.53s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:08<00:00,  8.14s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.25s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:08<00:00,  8.32s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.15s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.99s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.42s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.63s/it]\n","  0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([560, 480000])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:07<00:00,  7.52s/it]\n"]}]},{"cell_type":"markdown","source":["## **VERIFICAMOS EL PORCENTAJE DE EFECTIVIDAD DEL MODELO CON AMBOS GRUPOS PRUEBA Y ENTRENAMIENTO**"],"metadata":{"id":"ZsLSx99-CYI9"}},{"cell_type":"code","source":["# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    predicciones = []\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","            x = x.reshape(x.shape[0], -1)\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            predicciones.append(predictions)\n","\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","    model.train()\n","    return num_correct/num_samples, predicciones\n","\n","p_train, pred_train  = check_accuracy(train_loader, model)\n","p_test, pred_test  = check_accuracy(test_loader, model)\n","\n","print(f\"Accuracy on training set: {p_train*100:.2f}\")\n","print(f\"Accuracy on test set: {p_test*100:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeIdpntwau5g","executionInfo":{"status":"ok","timestamp":1714588677486,"user_tz":240,"elapsed":7467,"user":{"displayName":"Juan Sebastian Delgadillo Llanos","userId":"10436663413086141284"}},"outputId":"6f1cad2d-3cf7-4e1f-c8d3-41337566eda1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on training set: 83.04\n","Accuracy on test set: 53.57\n"]}]}]}